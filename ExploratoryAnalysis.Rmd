# Coursera-SwiftKey Milestone Report
####
####
#### Author: JiaHsuan Lo
#### Date: `r date()`

## Introduction

The purpose of this Cousera Capsotne project is to apply Natural Language Programming techniques to contruct a prediction model that is able to predict upcoming words based on previous words input by user. The training and test data is from a corpus called  HC Corpora [www.corpora.heliohost.org](www.corpora.heliohost.org). 

This milestone report will first demonstrates the findings in the initial exploratory data analysis. Then the goals and strategies of building the prediction model will be proposed. 

## Data Cleaning

The data was obtained from the Coursera site: [https://d396qusza40orc.cloudfront.net/dsscapstone/dataset/Coursera-SwiftKey.zip](https://d396qusza40orc.cloudfront.net/dsscapstone/dataset/Coursera-SwiftKey.zip)

Read data (Since the size of the data files is too large, the files were saved and access locally.)

* need to provide R file listing
* only english data were processed

``` {r readData, cache= TRUE}
# load utility functions
source("task1_tokenize.R")
source("task2_exploratory.R")

# assign data file names
fn_blogs<- "./final/en_US/en_US.blogs.txt"
fn_twitter<- "./final/en_US/en_US.twitter.txt"
fn_news<- "./final/en_US/en_US.news.txt"

# read lines
lines_blogs<- obtainLinesFast(fn_blogs)
lines_twitter<- obtainLinesFast(fn_twitter)
lines_news<- obtainLinesFast(fn_news)

# tokenize from lines
tkn_blogs<- obtainWordsFast(fn_blogs)
tkn_twitter<- obtainWordsFast(fn_twitter)
tkn_news<- obtainWordsFast(fn_news)

# build 2 gram vector
ng2_blogs<- buildNGramVector(tkn_blogs,n=2)
ng2_twitter<- buildNGramVector(tkn_twitter,n=2)
ng2_news<- buildNGramVector(tkn_news,n=2)



```