library(swirl)
swirl()
library(swirl)
swirl()
install_from_swirl("R Programming")
library(RMySQL)
ucscDb<- dbConnect(MySQL(), user= "genome", host= "genome-mysql.cse.ucsc.edu")
result<- dbGetQuery(ucscDb,"show databases"); dbDisconnect(ucscDb)
result
source("http://bioconductor.org/biocLite.R")
biocLite("rhdf5")
library(rhdf5)
con= url("http://scholar.google.com/citations?user=HI-I6C0AAAAJ&hl=en")
htmlCode= readLines(con)
library(XML)
url<- "http://m.espn.go.com/nba/teamstats?teamId=2&wjb"
html<- htmlTreeParse(url)
xpathSApply(html,"//title",xmlValue)
xpathSApply(html,"//title",xmlValue)
html<- htmlTreeParse(url, useInternalNodes = TRUE)
xpathSApply(html,"//title",xmlValue)
library(httr)
html2<- GET(url)
content2 <- content(html2,as="text")
parsedH<- htmlParse(content2, asText= TRUE)
xpathSApply(parseH,"//title", xmlValue)
xpathSApply(parsedH,"//title", xmlValue)
library(lattice)
library(datasets)
xyplot(Ozone~Wind, data=airquality)
airquality<- transform(airquality, Month= factor(Month))
xyplot(Ozone~Wind|Month, data= airquality, layout= c(5,1))
set.seed(10)
x<- rnorm(100)
f<- rep(0:1, each=50)
y<- x+f-f*x + rnorm(100,sd=0.5)
f<- factor(f, labels= c("Group 1","Group 2"))
xyplot(y~x|f, layout=c(2,1))
xyplot(y~x|f, panel= function(x,y,...){})
xyplot(y~x|f, panel= function(x,y,...){panel.xyplot(x,y,...) })
xyplot(y~x|f, panel= function(x,y,...){panel.xyplot(x,y,...) panel.abline(h=median(y), lty=2) })
xyplot(y~x|f, panel= function(x,y,...){panel.xyplot(x,y,...); panel.abline(h=median(y), lty=2) })
xyplot(y~x|f, panel= function(x,y,...){panel.xyplot(x,y,...); panel.lmline(x,y,col=2) })
install.packages("ggplot2")
install.packages("MASS")
install.packages("ggplot2")
library(ggplot2)
set.seed
set.seet(1234)
set.seed(1234)
x<- rnorm(12, mean= rep(1:3, each=4), sd=0.2)
y<- rnorm(12, mean= rep(c(1,2,1),each=4), sd=0.2)
df<- data.frame(x=x,y=y)
dist(df)
plot(x,y)
distxy<- dist(df)
hc<- hclust(distxy)
plot(hc)
set.seed(1234)
x<- rnorm(12, mean= rep(1:3,each=4), sd= 0.2)
y<- rnorm(12, mean= rep(c(1,2,1), each=4), sd=0.2)
plot(x,y)
df<- data.frame(x=x,y=y)
ko<- kmeans(df, centers = 3)
names(ko)
ko$cluster
plot(x,y,col=ko$cluster)
set.seed(12345)
dm<- matrix(rnorm(400), nrow = 40)
image(1:10, 1:40, t(dm)[,nrow(dm):1])
?image
heatmap(dm)
strsplit('fsdf.df',split='.')
strsplit('fsdf.df',split='\\.')
mylist<-strsplit('fsdf.df',split='\\.')
mylist
mpg
library(datasets)
names(mpg)
names(mad
)
n<- "this_is_a_test"
n
gsub("_","",n)
whos
ls()
library(datasets)
mpg
datasets::mpg
library(HistData)
names(mtcars)
grep("ar",names(mtcars))
grepl("ar",names(mtcars))
table(grepl("ar",names(mtcars)))
head(mtcars)
table(grepl("Mazda",mtcars[,0]))
table(grepl("Mazda",mtcars[,1]))
mtcars[,1]
mtcars[,0]
rownames(mtcars)
table(grepl("Mazda",rownames(mtcars))
)
grep("^Mazda",rownames(mtcars))
grep("Mazda",rownames(mtcars))
grep("[Mm][Aa][Zz][Dd][Aa]",rownames(mtcars))
grep("[Mm]azda",rownames(mtcars))
grep("^[Mm]a",rownames(mtcars))
grep("[0-9]",rownames(mtcars))
grep("[0-9]$",rownames(mtcars))
grep("[^0-9]$",rownames(mtcars))
rownames(mtcars)
grep("[^ ]",rownames(mtcars))
grep("[^"" ""]",rownames(mtcars))
grep("[^\\t]",rownames(mtcars))
grep("[\\S]",rownames(mtcars))
grep("[^\\s]",rownames(mtcars))
grep("\\S",rownames(mtcars))
grep("[:space:]",rownames(mtcars))
grep("[^:space:]",rownames(mtcars))
grep("[^[:space:]]",rownames(mtcars))
grep("[:space:]",rownames(mtcars))
grep("[[:space:]]",rownames(mtcars))
grep("^[[:space:]]",rownames(mtcars))
grep("\s",rownames(mtcars))
grep("\\s",rownames(mtcars))
grep("[^\\s]",rownames(mtcars))
grep("[\\s]",rownames(mtcars))
grep("[\s]",rownames(mtcars))
grep("\\s",rownames(mtcars))
grep("!\\s",rownames(mtcars))
grep("\\s",rownames(mtcars),value=TRUE)
grepl("\\s",rownames(mtcars))
!grepl("\\s",rownames(mtcars))
grepl("\\s",rownames(mtcars))==FALSE
grepl("^[\S]*$",rownames(mtcars))
grepl("^[\\S]*$",rownames(mtcars))
grepl("[\\S]*$",rownames(mtcars))
grepl("^*[\\S]*$",rownames(mtcars))
grepl("^[\\S]*$",rownames(mtcars))
grepl("^[\\s]*$",rownames(mtcars))
grepl("[\\s]*$",rownames(mtcars))
grepl("\\S",rownames(mtcars))
grepl("\\s",rownames(mtcars))
grepl("[:space:]",rownames(mtcars))
rownames(mtcars)
grep("1.9",rownames(mtcars))
grep("[Mm].c",rownames(mtcars))
grep("[Mm]..c",rownames(mtcars))
grep("Mazda|Merc",rownames(mtcars))
grep("[0-9*]$",rownames(mtcars))
grep("[0-9].[0-9]",rownames(mtcars))
grep("-",rownames(mtcars))
grep("( )",rownames(mtcars))
grep("(^ )",rownames(mtcars))
grep("(.*^ .*)",rownames(mtcars))
grep("(.*^ )",rownames(mtcars))
grep(".*(^ )",rownames(mtcars))
grep(".*(^ ).*",rownames(mtcars))
grep("\s",rownames(mtcars))
grep("\\s",rownames(mtcars))
grep("(^\\s)",rownames(mtcars))
grep("(\\s)",rownames(mtcars))
grep("(^(\\s))",rownames(mtcars))
grep("^.*+(^ )+.*",rownames(mtcars))
grep("^.*+(^ )",rownames(mtcars))
grep("^\\.*+(^ )+\\.*",rownames(mtcars))
grep(".*",rownames(mtcars))
grep("\s",rownames(mtcars))
grep("\\s",rownames(mtcars))
grep(".* \s",rownames(mtcars))
grep(".*\\s",rownames(mtcars))
grep(".*().*",rownames(mtcars))
grep(".*( ).*",rownames(mtcars))
grep(".*(^ ).*",rownames(mtcars))
grep(".*(^\\s).*",rownames(mtcars))
grep(".*(^\s).*",rownames(mtcars))
grep(".*(^s).*",rownames(mtcars))
grep(".* .*",rownames(mtcars))
grep(".*",rownames(mtcars))
grep("^.*$",rownames(mtcars))
grep("^.$",rownames(mtcars))
grep("^$",rownames(mtcars))
grep("^*$",rownames(mtcars))
grep("^.*.*$",rownames(mtcars))
grep("^.*$",rownames(mtcars))
grep("^.*[^ ].*$",rownames(mtcars))
grep("^.*[^\s].*$",rownames(mtcars))
grep("^.*[^\\s].*$",rownames(mtcars))
grep("^(\\S)*$",rownames(mtcars))
grep("\\S",rownames(mtcars))
grep("^.*\\S.*$",rownames(mtcars))
grep("^.*(\\S).*$",rownames(mtcars))
grep("^(\\S)$",rownames(mtcars))
grep("^(\\S).*$",rownames(mtcars))
grep("^(\\S)*$",rownames(mtcars))
d1<- date()
d1
d2= date()
d2
class(d2)
format(d2,"%a %b %d")
format(d1,"%a %b %d")
d1<- Sys.Date()
d1
format(d1,"%a %b %d")
install.packages("lubridate")
library(lubridate)
ymd(20150405)
library(caret)
install.packages("caret")
library(caret)
install.packages("kernlab")
library(kernlab)
data("spam")
inTrain<- createDataPartition(y=spam$type, p=0.75, list= FALSE)
training<- spam[inTrain,]
testing<- spam[-inTrain,]
hist(training$capitalAve,main="",xlab="ave cap run len")
set.seed(1234)
traing$capAve<- training$capitalAve
trainng$capAve<- training$capitalAve
trainng$capAve<- training$capitalAve
head(training)
training$capAve<- training$capitalAve
selectNA<- rbinom(dim(training)[1], size=1, prob=0.05)==1
rbinom(dim(training)[1], size=1, prob=0.05)
training$capAve[selectNA]<- NA
preObj<- preProcess(training[,-58], method = "knnImpute")
capAve<- predict(preObj, training[,-58])$capAve
install.packages("RANN")
library(RANN)
capAve<- predict(preObj, training[,-58])$capAve
spam$capitalAveSq<- spam$capitalAve^2
install.packages(ISLR)
install.packages("ISLR")
library(ISLR)
data("Wage")
inTrain<- createDataPartition(y=Wage$wage, p=0.7, list= FALSE)
training<- Wage[inTrain,]
testing<- Wage[-inTrain,]
table(training$jobclass)
dumm<- dummyVars(wage~jobclass, data= training)
head(predict(dumm, newdata=training))
nsv<- nearZeroVar(training, saveMetrics = TRUE)
nsv
library(splines)
bsBasis<- bs(training$age, df=3)
bsBasis
lm1<- lm(wage~bsBasis, data=training)
plot(training$age, training$wage, pch=19)
points(training$age, predict(lm1,newdata=training),col="red")
predict(bsBasis, age= testing$age)
library(ISLR)
library(ggplot2)
library(caret)
data("Wage")
Wage<- subset(Wage,select= -c(logwage))
summary(Wage)
inTrain<- createDataPartition(y=Wage$wage,p=0.7,list=FALSE)
training<- Wage[inTrain,]
testing<- Wage[-inTrain,]
dim(training)
dim(testing)
featurePlot(x=training[,c("age","education","jobclass")], y=training$wage, plot="pairs")
qplot(age,wage,data=training
)
qplot(age,wage,data=training,col=jobclass)
qplot(age,wage,data=training,col=education)
fit<- train(wage~age+jobclass+education,method="lm",data=training)
finMod<- fit$finalModel
print(fit)
plot(finMod,1,pch=19,cex=0.5)
qplot(finMod$fitted.values, finMod$residuals, col= race, data=training)
plot(finMod$residuals,pch=19)
pred<- predict(fit, testing)
qplot(wage,pred,col= year, data=testing)
library(AppliedPredictiveModeling)
library(caret)
data(AlzheimerDisease)
install.packages("AppliedPredictiveModeling")
library(AppliedPredictiveModeling)
library(caret)
data(AlzheimerDisease)
adData<- data.frame(diagnosis,predictors)
testIndex<- createDataPartition(diagnosis, p=0.5, list=FALSE)
training<- adData[-testIndex,]
testing<- adData[testIndex,]
dim(training)
dim(testing)
library(caret)
library(AppliedPredictiveModeling)
set.seed(3433)
data(AlzheimerDisease)
adData = data.frame(diagnosis,predictors)
inTrain = createDataPartition(adData$diagnosis, p = 3/4)[[1]]
training = adData[ inTrain,]
testing = adData[-inTrain,]
preProcess(training[,-1],method="pca")
class(training)
head(training)
nums<- sapply(training,is.numeric)
nums
td<- training[, nums]
head(td)
head(td[,1])
td[,1]
names(td)
pp<- preProcess(td,method="pca")
pp
?preProcess
pp<- preProcess(td,method="pca",thresh=0.90)
pp
str(td)
nameVec<- names(td)
nameVec
ind<- grep("IL",nameVec)
ind
pp<- preProcess(td[,ind],method="pca",thresh=0.90)
pp
str(td[,ind])
ind<- grep("^IL",nameVec)
str(td[,ind])
pp<- preProcess(td[,ind],method="pca",thresh=0.90)
pp
library(caret)
library(AppliedPredictiveModeling)
set.seed(3433)
data(AlzheimerDisease)
adData = data.frame(diagnosis,predictors)
inTrain = createDataPartition(adData$diagnosis, p = 3/4)[[1]]
training = adData[ inTrain,]
testing = adData[-inTrain,]
nameVec<- names(training)
ind<- grep("^IL",nameVec)
td<- training[,ind]
pp<- preProcess(td,thresh = 0.8, method = "pca")
pp
pp<- preProcess(td, method = "pca", pcaComp = 7)
trainPC<- predict(pp,td)
modPCA<-train(training$diagnosis~. method="glm",data=trainPC)
modPCA<-train(training$diagnosis~. methods()="glm",data=trainPC)
modPCA<-train(training$diagnosis~. ,method="glm",data=trainPC)
install.packages("e1071")
modPCA<-train(training$diagnosis~. ,method="glm",data=trainPC)
testPC<- predict(pp,testing[,ind])
confusionMatrix(testing$diagnosis,predict(modPCA,testPC))
modAll<-train(training$diagnosis~. ,method="glm",data=td)
confusionMatrix(testing$diagnosis, predict(modAll,testing[,ind]))
library(swirl)
swirl()
library(swirl)
swirl()
swirl()
5+7
x<- 5+7
x
data("mtcars")
pairs(mtcars)
str(mtcars)
?mtcars
cor(mrcats[,1:7])
cor(mtcars[,1:7])
pairs(mtcars[,1:7])
install.packages("car")
head(mtcars)
cor(mtcars)
pairs(mtcars[,c(1,2,3,4,5,6,7,9)])
library(GGally)
g<- ggpairs(mtcars)
g
library(MASS)
head(shuttle)
mod<- glm(use~wind+magn)
mod<- glm(use~wind+magn,data=shuttle,family="binomial")
summary(mod)
exp(summary(mod$coefficients))
exp(summary(summary(mod)$coefficients))
exp(summary(summary(mod)$coef))
exp(summary(mod)$coef))
exp(summary(mod)$coef)
1/0.9684981
mod0<- glm(use~wind,data=shuttle,family="binomial")
exp(summary(mod)$coef)
head(shuttle)
str(shuttle)
mod0<- glm(shuttle$use~shuttle$wind,family="binomial")
exp(summary(mod)$coef)
(summary(mod)$coef)
exp(1/summary(mod)$coef)
library(swirl)
swirl()
View(ravenData)
mdl<- glm(ravenWinNum~ravenScore, family="binomial", data=ravenData)
library(MASS)
head(shuttle)
str(shuttle)
levels(shuttle$use)
head(shuttle)
summary(shuttle$wind)
?glm
(summary(mod)$coef)
q()
set.seed(3523)
library(AppliedPredictiveModeling)
data(concrete)
inTrain = createDataPartition(concrete$CompressiveStrength, p = 3/4)[[1]]
training = concrete[ inTrain,]
testing = concrete[-inTrain,]
library(caret)
set.seed(3523)
library(AppliedPredictiveModeling)
data(concrete)
inTrain = createDataPartition(concrete$CompressiveStrength, p = 3/4)[[1]]
training = concrete[ inTrain,]
testing = concrete[-inTrain,]
set.seed(325)
?svm
library(e1071)
?svm
head(training)
modS<- svm(training[,-9],training$CompressiveStrength)
pred<- predict(mods,testing[,-9])
pred<- predict(modS,testing[,-9])
confusionMatrix(pred,testing$CompressiveStrength)
confusionMatrix(testing$CompressiveStrength,pred)
pred
pred<- predict(modS,testing)
pred<- predict(modS,testing[,-9])
pred0<- predict(modS,training[,-9])
confusionMatrix(pred0,training[,9])
confusionMatrix(pred0,training)
?confusionMatrix
head(training)
table(pred,testing[,9])
head(training)
pred
err<- pred-testing$CompressiveStrength
rmse(err)
RMSE(err)
RMSE(pred = pred, obs = testing$CompressiveStrength)
set.seed(3523)
library(AppliedPredictiveModeling)
data(concrete)
inTrain = createDataPartition(concrete$CompressiveStrength, p = 3/4)[[1]]
training = concrete[ inTrain,]
testing = concrete[-inTrain,]
set.seed(233)
fitL<- train(CompressiveStrength~., data=training, method="lasso")
set.seed(233)
fitL<- train(CompressiveStrength~., data=training, method="lasso")
plot(fitL,"penalty")
plot(fitL)
?plot.enet
plot(fitL, xvar="penalty")
fitL
plot(fitL$finalModel, xvar="penalty")
x<-rnorm(100)
y<- rnorm(100)
fit<- lm(y~x)
class(fit)
mean
set(seed(2))
set.seed(2)
x<-rnorm(100)
mean(x)
head(getS3method(("mean","default")),10)
head(getS3method("mean","default"),10)
set.seed(3)
df<- data.frame(x= rnorm(100),x=1:100)
sapply(df,mean)
setClass("polygon", representation = (x= "numeric", y="numeric"))
setClass("polygon", representation = (x= "numeric", y="numeric"))
setClass("polygon", representation(x= "numeric", y="numeric"))
setMethod("plot","polygon,")
setMethod("plot","polygon,"
)
setMethod("plot","polygon",
function(x,y,...){}
)
setMethod("plot","polygon",
function(x,y,...){
plot(x@x,x@y, type="n",...)
xp<- c(x@x, x@x[1])
yp<- c(x@y, x@y[1])
lines(xp,yp)
})
p<- new("polygon", x=c(1,2,3,4), y(1,2,3,1))
p<- new("polygon", x=c(1,2,3,4), y=c(1,2,3,1))
plot(p)
?plot
?mean
?colSums
?dgamma
?mean
setwd("/home/jlo/Documents/RFiles/DataScienceCapstone")
library(slidify)
library(devtools)
install_github("slidify","ramnathv")
library(slidify)
author("NextWordSlides")
install_github("ramnathv/slidify")
library("slidify")
install_github("slidifyLibraries","ramnathv")
install_github('slidifyLibraries', 'ramnathv')
install_github('ramnathv\slidifyLibraries')
install_github('ramnathv/slidifyLibraries')
library(slidifyLibraries)
